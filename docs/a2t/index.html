<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>a2t API documentation</title>
<meta name="description" content="This repository contains the code for out of the box ready to use zero-shot classifiers among different tasks,
such as Topic Labelling or Relation â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>a2t</code></h1>
</header>
<section id="section-intro">
<p>This repository contains the code for out of the box ready to use zero-shot classifiers among different tasks,
such as Topic Labelling or Relation Extraction. It is built on top of ðŸ¤— HuggingFace <a href="https://github.com/huggingface/transformers">Transformers</a>
library, so you are free to choose among hundreds of models. You can either, use a dataset specific classifier or define one
yourself with just labels descriptions or templates!</p>
<h2 id="installation">Installation</h2>
<p>By using Pip (check the last release)</p>
<pre><code class="language-shell">pip install a2t
</code></pre>
<p>Or by clonning the repository from
<img
src="https://raw.githubusercontent.com/gilbarbara/logos/master/logos/github-icon.svg"
width="25" height="25" href="https://github.com/osainz59/Ask2Transformers" />
<a href="https://github.com/osainz59/Ask2Transformers">GitHub</a>:</p>
<pre><code class="language-shell">git clone https://github.com/osainz59/Ask2Transformers.git
cd Ask2Transformers
python -m pip install .
</code></pre>
<h2 id="getting-started">Getting Started</h2>
<p>The framework is organized to differentiate <strong>three</strong> main components: the <strong>data</strong>, <strong>task</strong> and <strong>inference</strong>.
Let's define a Topic Classifier that will classify sentences into the following topics: Politics, Culture, Economy,
Biology, Legal, Medicine and Business.</p>
<h3 id="defining-the-dataset">Defining the dataset</h3>
<p>We will create a dummy dataset with only one instance to test our model. The <code>Dataset</code> object is intended to be
used to load some data from a file and create the task features.</p>
<pre><code class="language-python">from a2t.data import Dataset
from a2t.tasks import TopicClassificationFeatures

labels = [
    'politics', 'culture', 'economy', 'biology', 'legal', 'medicine', 'business'
]

class DummyTopicClassificationDataset(Dataset):
    def __init__(self) -&gt; None:
        super().__init__(labels=labels)

        self.append(
            TopicClassificationFeatures(
                context=&quot;hospital: a health facility where patients&quot;
                        &quot; receive treatment.&quot;,
                label=&quot;medicine&quot;
            )
        )

dataset = DummyTopicClassificationDataset()
</code></pre>
<p>You do not actually need to define a dataset, just a list of <code>Features</code> is enough.</p>
<h3 id="defining-the-task">Defining the Task</h3>
<p>The <code>Task</code> object will contain the <strong>label verbalizations</strong> and other task specific information. In this case it will be just the
labels that we defined before. For more complex tasks like Relation Extraction you will probably need to define a set of <code>templates</code>
and <code>valid_conditions</code>. This object should contain all the information regarding the task like the schema or ontology.</p>
<pre><code class="language-python">from a2t.tasks import TopicClassificationTask

task = TopicClassificationTask(name=&quot;DummyTopic task&quot;, labels=labels)
</code></pre>
<h3 id="defining-the-inference">Defining the inference</h3>
<p>The <code>EntailmentClassifier</code> object should be instantiated with the information about the pre-trained model and device information. You can
make use of any entailment model available on ðŸ¤— <a href="https://github.com/huggingface/transformers">Transformers</a> that was
trained on some NLI dataset.</p>
<pre><code class="language-python">from a2t.base import EntailmentClassifier

nlp = EntailmentClassifier(
    'roberta-large-mnli', 
    use_tqdm=False, 
    use_cuda=True, 
    half=True
)
</code></pre>
<h3 id="putting-all-together">Putting all together</h3>
<p>The following code is enough to run the model:</p>
<pre><code class="language-python">predictions = nlp(
    task=task, 
    features=dataset, 
    return_labels=True, 
    return_confidences=True, 
    topk=3
)

print(predictions)
</code></pre>
<p>The result should be something close to this:</p>
<pre><code class="language-python">[
    [('medicine', 0.8545), ('biology', 0.03693), ('business', 0.0322)]
]
</code></pre>
<h2 id="information-extraction-with-entailment">Information Extraction with Entailment</h2>
<p>On the previous example we already saw how to create a Topic Classifier that will classify the whole given text into a set of topic labels.
That kind of tasks are known as <strong>Text Classification</strong> tasks. On Information Extraction (IE) instead, we usually find tasks that require
to classify spans inside a sentence (<strong>Span Classification</strong> tasks like NER) or relations between spans inside a sentence/document (<strong>Tuple
Classification tasks</strong> like Relation Extraction). This framework differentiates the task types by the number of spans involved: if no spans
are involved are <code>ZeroaryTask</code>, if 1 span is involved are <code>UnaryTask</code> and if 2 spans are involved the tasks are <code>BinaryTask</code>.</p>
<p>Let's build an small Relation Classifier based on <a href="https://aclanthology.org/2021.emnlp-main.92/">Sainz et al. (2021)</a>:</p>
<h3 id="defining-the-templates-for-the-task">Defining the templates for the task</h3>
<p>We are going to build a small classifier that will classify entity pairs into the next relations:</p>
<ul>
<li><code>per:city_of_death</code>: The <code>X</code> entity died in <code>Y</code> and <code>Y</code> is a city.</li>
<li><code>org:founded_by</code>: The <code>X</code> organization was founded by <code>Y</code> person.</li>
<li><code>no_relation</code>: No relation (among the predefined relations) exists between <code>X</code> and <code>Y</code>.</li>
</ul>
<pre><code class="language-python">labels = [&quot;no_relation&quot;, &quot;per:city_of_death&quot;, &quot;org:founded_by&quot;]
</code></pre>
<p>Then, we need to define the set of templates that verbalize each relation. These templates must contain <strong>placeholders</strong> for
two entity spans. In this case, we are going to use <code>X</code> and <code>Y</code> as they are already defined on <code>BinaryFeatures</code>.</p>
<pre><code class="language-python">templates = {
    &quot;per:city_of_death&quot;: [
        &quot;{X} died in {Y}&quot;
    ],
    &quot;org:founded_by&quot;: [
        &quot;{X} was founded by {Y}&quot;,
        &quot;{Y} founded {X}&quot;
    ]
}
</code></pre>
<p>We can also define a set of constraints to each of the labels to simplify the templates. For example, on <a href="https://nlp.stanford.edu/projects/tacred/">TACRED</a>
exists both <code>per:city_of_death</code> and <code>per:country_of_death</code>, we could use the template <code>"{X} died in {Y}"</code> for both and differentiate them adding the
<code>"PERSON:CITY"</code> constraint to <code>per:city_of_death</code> as follows:</p>
<pre><code class="language-python">valid_conditions = {
    &quot;per:city_of_death&quot;: [
        &quot;PERSON:CITY&quot;,
        &quot;PERSON:LOCATION&quot;
    ],
    &quot;org:founded_by&quot;: [
        &quot;ORGANIZATION:PERSON&quot;
    ]
}
</code></pre>
<p>Once we defined our <strong>labels</strong>, <strong>templates</strong> and <strong>constraints</strong> we can define our task as follows:</p>
<pre><code class="language-python">from a2t.tasks import BinaryTask, BinaryFeatures

task = BinaryTask(
    name=&quot;Relation Classification task&quot;,
    required_variables=[&quot;X&quot;, &quot;Y&quot;],
    additional_variables=[&quot;inst_type&quot;],
    labels=labels,
    templates=templates,
    valid_conditions=valid_conditions,
    negative_label_id=0,
    multi_label=True,
    features_class=BinaryFeatures
)
</code></pre>
<h3 id="testing-the-relation-classifier">Testing the Relation Classifier</h3>
<p>At this point we have all we need to perform inferences on this task, let's see how it actually works:</p>
<pre><code class="language-python">from a2t.base import EntailmentClassifier

nlp = EntailmentClassifier(
    &quot;microsoft/deberta-v2-xlarge-mnli&quot;,
    use_tqdm=False,
    use_cuda=True, 
    half=True
)

test_examples = [
    BinaryFeatures(X='Billy Mays', Y='Tampa', inst_type='PERSON:CITY', context='Billy Mays, the bearded, boisterous pitchman who, as the undisputed king of TV yell and sell, became an unlikely pop culture icon, died at his home in Tampa, Fla, on Sunday', label='per:city_of_death'),
    BinaryFeatures(X='Old Lane Partners', Y='Pandit', inst_type='ORGANIZATION:PERSON', context='Pandit worked at the brokerage Morgan Stanley for about 11 years until 2005, when he and some Morgan Stanley colleagues quit and later founded the hedge fund Old Lane Partners.', label='org:founded_by'),
    BinaryFeatures(X='He', Y='University of Maryland in College Park', inst_type='PERSON:ORGANIZATION', context='He received an undergraduate degree from Morgan State University in 1950 and applied for admission to graduate school at the University of Maryland in College Park.', label='no_relation')
]

nlp(task=task, features=test_examples, return_labels=True, return_confidences=True)
</code></pre>
<p>The output should look like:</p>
<pre><code class="language-python">[('per:city_of_death', 0.98828125),
 ('org:founded_by', 0.955078125),
 ('no_relation', 1.0)]
</code></pre>
<p>For more information consider reading the <a href="tasks/index.html">Tasks</a> documentation.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;This repository contains the code for out of the box ready to use zero-shot classifiers among different tasks, 
such as Topic Labelling or Relation Extraction. It is built on top of ðŸ¤— HuggingFace [Transformers](https://github.com/huggingface/transformers) 
library, so you are free to choose among hundreds of models. You can either, use a dataset specific classifier or define one 
yourself with just labels descriptions or templates!

## Installation

By using Pip (check the last release)

```shell
pip install a2t
```

Or by clonning the repository from 
&lt;img 
    src=&#34;https://raw.githubusercontent.com/gilbarbara/logos/master/logos/github-icon.svg&#34; 
    width=&#34;25&#34; height=&#34;25&#34; href=&#34;https://github.com/osainz59/Ask2Transformers&#34; /&gt; 
[GitHub](https://github.com/osainz59/Ask2Transformers):

```shell
git clone https://github.com/osainz59/Ask2Transformers.git
cd Ask2Transformers
python -m pip install .
```

## Getting Started

The framework is organized to differentiate **three** main components: the **data**, **task** and **inference**. 
Let&#39;s define a Topic Classifier that will classify sentences into the following topics: Politics, Culture, Economy, 
Biology, Legal, Medicine and Business.

### Defining the dataset

We will create a dummy dataset with only one instance to test our model. The `Dataset` object is intended to be 
used to load some data from a file and create the task features.

```python
from a2t.data import Dataset
from a2t.tasks import TopicClassificationFeatures

labels = [
    &#39;politics&#39;, &#39;culture&#39;, &#39;economy&#39;, &#39;biology&#39;, &#39;legal&#39;, &#39;medicine&#39;, &#39;business&#39;
]

class DummyTopicClassificationDataset(Dataset):
    def __init__(self) -&gt; None:
        super().__init__(labels=labels)

        self.append(
            TopicClassificationFeatures(
                context=&#34;hospital: a health facility where patients&#34;
                        &#34; receive treatment.&#34;,
                label=&#34;medicine&#34;
            )
        )

dataset = DummyTopicClassificationDataset()
```

You do not actually need to define a dataset, just a list of `Features` is enough.

### Defining the Task

The `Task` object will contain the **label verbalizations** and other task specific information. In this case it will be just the 
labels that we defined before. For more complex tasks like Relation Extraction you will probably need to define a set of `templates` 
and `valid_conditions`. This object should contain all the information regarding the task like the schema or ontology.

```python
from a2t.tasks import TopicClassificationTask

task = TopicClassificationTask(name=&#34;DummyTopic task&#34;, labels=labels)
```

### Defining the inference

The `EntailmentClassifier` object should be instantiated with the information about the pre-trained model and device information. You can 
make use of any entailment model available on ðŸ¤— [Transformers](https://github.com/huggingface/transformers) that was
trained on some NLI dataset.

```python
from a2t.base import EntailmentClassifier

nlp = EntailmentClassifier(
    &#39;roberta-large-mnli&#39;, 
    use_tqdm=False, 
    use_cuda=True, 
    half=True
)
```

### Putting all together

The following code is enough to run the model:

```python
predictions = nlp(
    task=task, 
    features=dataset, 
    return_labels=True, 
    return_confidences=True, 
    topk=3
)

print(predictions)
```
The result should be something close to this:
```python
[
    [(&#39;medicine&#39;, 0.8545), (&#39;biology&#39;, 0.03693), (&#39;business&#39;, 0.0322)]
]
```

## Information Extraction with Entailment

On the previous example we already saw how to create a Topic Classifier that will classify the whole given text into a set of topic labels.
That kind of tasks are known as **Text Classification** tasks. On Information Extraction (IE) instead, we usually find tasks that require 
to classify spans inside a sentence (**Span Classification** tasks like NER) or relations between spans inside a sentence/document (**Tuple 
Classification tasks** like Relation Extraction). This framework differentiates the task types by the number of spans involved: if no spans 
are involved are `ZeroaryTask`, if 1 span is involved are `UnaryTask` and if 2 spans are involved the tasks are `BinaryTask`.

Let&#39;s build an small Relation Classifier based on [Sainz et al. (2021)](https://aclanthology.org/2021.emnlp-main.92/):

### Defining the templates for the task

We are going to build a small classifier that will classify entity pairs into the next relations:

* `per:city_of_death`: The `X` entity died in `Y` and `Y` is a city.
* `org:founded_by`: The `X` organization was founded by `Y` person.
* `no_relation`: No relation (among the predefined relations) exists between `X` and `Y`.

```python
labels = [&#34;no_relation&#34;, &#34;per:city_of_death&#34;, &#34;org:founded_by&#34;]
```

Then, we need to define the set of templates that verbalize each relation. These templates must contain **placeholders** for
two entity spans. In this case, we are going to use `X` and `Y` as they are already defined on `BinaryFeatures`.

```python
templates = {
    &#34;per:city_of_death&#34;: [
        &#34;{X} died in {Y}&#34;
    ],
    &#34;org:founded_by&#34;: [
        &#34;{X} was founded by {Y}&#34;,
        &#34;{Y} founded {X}&#34;
    ]
}
```
We can also define a set of constraints to each of the labels to simplify the templates. For example, on [TACRED](https://nlp.stanford.edu/projects/tacred/)
exists both `per:city_of_death` and `per:country_of_death`, we could use the template `&#34;{X} died in {Y}&#34;` for both and differentiate them adding the 
`&#34;PERSON:CITY&#34;` constraint to `per:city_of_death` as follows:

```python
valid_conditions = {
    &#34;per:city_of_death&#34;: [
        &#34;PERSON:CITY&#34;,
        &#34;PERSON:LOCATION&#34;
    ],
    &#34;org:founded_by&#34;: [
        &#34;ORGANIZATION:PERSON&#34;
    ]
}
```

Once we defined our **labels**, **templates** and **constraints** we can define our task as follows:

```python
from a2t.tasks import BinaryTask, BinaryFeatures

task = BinaryTask(
    name=&#34;Relation Classification task&#34;,
    required_variables=[&#34;X&#34;, &#34;Y&#34;],
    additional_variables=[&#34;inst_type&#34;],
    labels=labels,
    templates=templates,
    valid_conditions=valid_conditions,
    negative_label_id=0,
    multi_label=True,
    features_class=BinaryFeatures
)
```

### Testing the Relation Classifier

At this point we have all we need to perform inferences on this task, let&#39;s see how it actually works:

```python
from a2t.base import EntailmentClassifier

nlp = EntailmentClassifier(
    &#34;microsoft/deberta-v2-xlarge-mnli&#34;,
    use_tqdm=False,
    use_cuda=True, 
    half=True
)

test_examples = [
    BinaryFeatures(X=&#39;Billy Mays&#39;, Y=&#39;Tampa&#39;, inst_type=&#39;PERSON:CITY&#39;, context=&#39;Billy Mays, the bearded, boisterous pitchman who, as the undisputed king of TV yell and sell, became an unlikely pop culture icon, died at his home in Tampa, Fla, on Sunday&#39;, label=&#39;per:city_of_death&#39;),
    BinaryFeatures(X=&#39;Old Lane Partners&#39;, Y=&#39;Pandit&#39;, inst_type=&#39;ORGANIZATION:PERSON&#39;, context=&#39;Pandit worked at the brokerage Morgan Stanley for about 11 years until 2005, when he and some Morgan Stanley colleagues quit and later founded the hedge fund Old Lane Partners.&#39;, label=&#39;org:founded_by&#39;),
    BinaryFeatures(X=&#39;He&#39;, Y=&#39;University of Maryland in College Park&#39;, inst_type=&#39;PERSON:ORGANIZATION&#39;, context=&#39;He received an undergraduate degree from Morgan State University in 1950 and applied for admission to graduate school at the University of Maryland in College Park.&#39;, label=&#39;no_relation&#39;)
]

nlp(task=task, features=test_examples, return_labels=True, return_confidences=True)
```

The output should look like:

```python
[(&#39;per:city_of_death&#39;, 0.98828125),
 (&#39;org:founded_by&#39;, 0.955078125),
 (&#39;no_relation&#39;, 1.0)]
```

For more information consider reading the [Tasks](tasks/index.html) documentation. 
&#34;&#34;&#34;

__version__ = &#34;0.3.0&#34;

__pdoc__ = {
    &#34;legacy&#34;: False,
    &#34;evaluation&#34;: True,
    &#34;tests&#34;: False,
    &#34;tasks.base&#34;: False,
    &#34;tasks.span_classification&#34;: False,
    &#34;tasks.text_classification&#34;: False,
    &#34;tasks.tuple_classification&#34;: False,
    &#34;base.np_softmax&#34;: False,
    &#34;base.np_sigmoid&#34;: False,
    &#34;data.base&#34;: False,
    &#34;data.tacred&#34;: False,
    &#34;utils&#34;: False,
    &#34;base.Classifier&#34;: False,
}</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="a2t.base" href="base.html">a2t.base</a></code></dt>
<dd>
<div class="desc"><p>The module <code><a title="a2t.base" href="base.html">a2t.base</a></code> implements all the basic methods to perform the inference, including the <code>EntailmentClassifier</code>.</p></div>
</dd>
<dt><code class="name"><a title="a2t.data" href="data/index.html">a2t.data</a></code></dt>
<dd>
<div class="desc"><p>The module <code><a title="a2t.data" href="data/index.html">a2t.data</a></code> implements different dataloaders or <code>Dataset</code>s for predefined tasks.</p></div>
</dd>
<dt><code class="name"><a title="a2t.evaluation" href="evaluation.html">a2t.evaluation</a></code></dt>
<dd>
<div class="desc"><p>Main evaluation script â€¦</p></div>
</dd>
<dt><code class="name"><a title="a2t.pipeline" href="pipeline/index.html">a2t.pipeline</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="a2t.tasks" href="tasks/index.html">a2t.tasks</a></code></dt>
<dd>
<div class="desc"><p>The module <code><a title="a2t.tasks" href="tasks/index.html">a2t.tasks</a></code> contains the code related to the <code>Task</code> definition â€¦</p></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#installation">Installation</a></li>
<li><a href="#getting-started">Getting Started</a><ul>
<li><a href="#defining-the-dataset">Defining the dataset</a></li>
<li><a href="#defining-the-task">Defining the Task</a></li>
<li><a href="#defining-the-inference">Defining the inference</a></li>
<li><a href="#putting-all-together">Putting all together</a></li>
</ul>
</li>
<li><a href="#information-extraction-with-entailment">Information Extraction with Entailment</a><ul>
<li><a href="#defining-the-templates-for-the-task">Defining the templates for the task</a></li>
<li><a href="#testing-the-relation-classifier">Testing the Relation Classifier</a></li>
</ul>
</li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="a2t.base" href="base.html">a2t.base</a></code></li>
<li><code><a title="a2t.data" href="data/index.html">a2t.data</a></code></li>
<li><code><a title="a2t.evaluation" href="evaluation.html">a2t.evaluation</a></code></li>
<li><code><a title="a2t.pipeline" href="pipeline/index.html">a2t.pipeline</a></code></li>
<li><code><a title="a2t.tasks" href="tasks/index.html">a2t.tasks</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>